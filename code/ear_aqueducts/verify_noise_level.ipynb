{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify noise level for 5 noise cases\n",
    "- 10\\%\n",
    "- 20\\%\n",
    "- STD from data\n",
    "- avg STD from data\n",
    "- avg over time from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import cuqi\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from cuqi.distribution import Gaussian, JointDistribution\n",
    "from cuqi.geometry import Continuous2D\n",
    "from cuqi.pde import TimeDependentLinearPDE\n",
    "from cuqi.model import PDEModel\n",
    "from advection_diffusion_inference_utils import parse_commandline_args,\\\n",
    "    read_data_files,\\\n",
    "    create_domain_geometry,\\\n",
    "    create_PDE_form,\\\n",
    "    create_prior_distribution,\\\n",
    "    create_exact_solution_and_data,\\\n",
    "    set_the_noise_std,\\\n",
    "    sample_the_posterior,\\\n",
    "    create_experiment_tag,\\\n",
    "    plot_experiment,\\\n",
    "    save_experiment_data,\\\n",
    "    Args,\\\n",
    "    build_grids,\\\n",
    "    create_time_steps,\\\n",
    "    plot_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up run arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "noise_level_list= [\"fromDataVar\" , \"fromDataAvg\", \"avgOverTime\", 0.1, 0.2]\n",
    "args.noise_level = noise_level_list[3]\n",
    "args.animal = 'm1'\n",
    "args.ear = 'l'\n",
    "args.num_ST = 4\n",
    "args.inference_type = 'heterogeneous'\n",
    "args.unknown_par_type = 'sampleMean'\n",
    "args.unknown_par_value = ['m1:l:NUTS:constant:100.0:real:heterogeneous:1000:0.1:v:April22:2024:a::4:5@../../../Collab-BrainEfflux-Data/April_2x_2024_b']\n",
    "\n",
    "tag = create_experiment_tag(args)\n",
    "print(tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times, locations, real_data, real_std_data = read_data_files(args)\n",
    "# The left boundary condition is given by the data  \n",
    "real_bc = real_data.reshape([len(locations), len(times)])[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STEP 4: Create the PDE grid and coefficients grid\n",
    "#----------------------------------------------------\n",
    "# PDE and coefficients grids\n",
    "L = locations[-1]*1.3\n",
    "coarsening_factor = 5\n",
    "n_grid_c = 20\n",
    "grid, grid_c, grid_c_fine, h, n_grid = build_grids(L, coarsening_factor, n_grid_c)\n",
    "\n",
    "#%% STEP 5: Create the PDE time steps array\n",
    "#------------------------------------------\n",
    "tau_max = 30*60 # Final time in sec\n",
    "cfl = 5 # The cfl condition to have a stable solution\n",
    "         # the method is implicit, we can choose relatively large time steps \n",
    "tau = create_time_steps(h, cfl, tau_max)\n",
    "\n",
    "#%% STEP 6: Create the domain geometry\n",
    "#-------------------------------------\n",
    "G_c = create_domain_geometry(grid_c, args.inference_type)\n",
    "\n",
    "# STEP 7: Create the PDE form\n",
    "#----------------------------\n",
    "PDE_form = create_PDE_form(real_bc, grid, grid_c, grid_c_fine, n_grid, h, times,\n",
    "                           args.inference_type)\n",
    "\n",
    "# STEP 8: Create the CUQIpy PDE object\n",
    "#-------------------------------------\n",
    "PDE = TimeDependentLinearPDE(PDE_form,\n",
    "                             tau,\n",
    "                             grid_sol=grid,\n",
    "                             method='backward_euler', \n",
    "                             grid_obs=locations,\n",
    "                             time_obs=times) \n",
    "\n",
    "# STEP 9: Create the range geometry\n",
    "#----------------------------------\n",
    "G_cont2D = Continuous2D((locations, times))\n",
    "\n",
    "# STEP 10: Create the CUQIpy PDE model\n",
    "#-------------------------------------\n",
    "A = PDEModel(PDE, range_geometry=G_cont2D, domain_geometry=G_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 11: Create the prior distribution\n",
    "#---------------------------------------\n",
    "x = create_prior_distribution(G_c, args.inference_type)\n",
    "\n",
    "#from cuqi.distribution import GMRF\n",
    "#x = GMRF(np.ones(G_c.par_dim)*np.sqrt(300), 0.2, geometry=G_c, bc_type='neumann')\n",
    "\n",
    "Ns = 10\n",
    "samples_x = x.sample(Ns)\n",
    "samples_x.plot(range(Ns), plot_par=True)\n",
    "plt.figure()\n",
    "samples_x.funvals.plot(range(Ns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and plot exact data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_true, exact_data = create_exact_solution_and_data(A, args.unknown_par_type, args.unknown_par_value)\n",
    "plot_time_series(times, locations, exact_data.reshape([len(locations), len(times)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STEP 13: Create the data distribution\n",
    "#----------------------------------------\n",
    "# First, illustrate how different noise levels setups affect the std\n",
    "print(\"Standard deviation values\")\n",
    "plt.figure()\n",
    "for item in noise_level_list:\n",
    "    s_noise_temp = set_the_noise_std(\n",
    "        args.data_type, item, exact_data,\n",
    "        None, real_std_data, G_cont2D)\n",
    "    print('\\n**noise_level option**:', item)\n",
    "    print('**STD of the noise**:')\n",
    "    print(s_noise_temp)\n",
    "    # plot noise level\n",
    "    if isinstance(s_noise_temp, np.ndarray):\n",
    "        plt.plot(s_noise_temp, label=str(item))\n",
    "    else:\n",
    "        plt.plot(s_noise_temp*np.ones(G_cont2D.par_dim), label=str(item))\n",
    "plt.legend()\n",
    "plt.title('Noise level')\n",
    "plt.xlabel('data point index i\\n data point for the same location are grouped together')\n",
    "plt.ylabel('std of the noise')\n",
    "\n",
    "# Second, set the noise level\n",
    "s_noise = set_the_noise_std(args.data_type, args.noise_level, exact_data,\n",
    "                                None, real_std_data, G_cont2D)\n",
    "y = Gaussian(A(x), s_noise**2, geometry=G_cont2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples of noisy data and plot the noisy data and the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = y(x=x_true).sample()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 3))\n",
    "plt.sca(ax[0])\n",
    "plot_time_series(times, locations, exact_data.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "plt.title('Exact data')\n",
    "\n",
    "plt.sca(ax[1])\n",
    "plot_time_series(times, locations, noisy_data.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "plt.title('Noisy data')\n",
    "\n",
    "diff = noisy_data - exact_data\n",
    "plt.sca(ax[2])\n",
    "lines, labels = plot_time_series(times, locations, diff.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "plt.title('Difference')\n",
    "# Noise to signal ratio\n",
    "print('Noise to signal ratio (synthitic data): ', np.linalg.norm(diff)/np.linalg.norm(noisy_data))\n",
    "print('STD to signal ratio (real data): ', np.linalg.norm(real_std_data)/np.linalg.norm(real_data))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "# turn off axis\n",
    "plt.axis('off')\n",
    "plt.legend(lines, labels, loc='center',ncol=3)\n",
    "#figure size\n",
    "fig2.set_size_inches(14, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How subsampling the data affects the noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume we have n observations of the same value\n",
    "# The values is 7\n",
    "sl = [2, 4] # number of points to average in the subsample\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "ns = [40*k for k in range(1,10)]\n",
    "stds_sub = np.empty((len(sl), len(ns)))\n",
    "for i, n in enumerate(ns):\n",
    "  value = 7\n",
    "  obs = value + np.random.randn(n)*0.1\n",
    "  for j, n_subsample in enumerate(sl):\n",
    "    # average the observations\n",
    "    obs_sub = np.mean(obs.reshape(-1, n_subsample), axis=1)\n",
    "    stds_sub[j, i] = np.std(obs_sub)\n",
    "\n",
    "  means.append(np.mean(obs))\n",
    "  stds.append(np.std(obs))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 3))\n",
    "plt.sca(ax[0])\n",
    "plt.plot(ns, means, 'o', label='mean')\n",
    "plt.plot(ns,[value]*len(means), 'r--', label='true value')\n",
    "plt.legend()\n",
    "plt.sca(ax[1])\n",
    "plt.plot(ns, stds, 'o', label='std')\n",
    "for l in range(len(sl)):\n",
    "  plt.plot(ns, stds_sub[l], 'o', label='std subsample'+str(sl[l]))\n",
    "plt.plot(ns, [0.1]*len(stds), 'r--', label='true std')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A note on reducing the noise level by averaging\n",
    "\n",
    "# Assume we have n measurements of the same value, true value is 7\n",
    "true_value = 7\n",
    "n = 9\n",
    "\n",
    "# Assume the standard deviation of the measurement noise is 0.1\n",
    "std = 0.1\n",
    "\n",
    "# The measurements\n",
    "measurement_noise = np.random.normal(size=n)*std\n",
    "measurement = true_value + measurement_noise\n",
    "\n",
    "# The measurements follow a Gaussian distribution\n",
    "x_1 = Gaussian(true_value*np.ones(n), std**2)\n",
    "\n",
    "# The mean of the measurements follows a Gaussian distribution, note\n",
    "# the factor 1/sqrt(n) in the standard deviation\n",
    "x_2 = Gaussian(true_value*np.ones(1), (std/np.sqrt(n))**2)\n",
    "\n",
    "# Plot samples from the two distributions\n",
    "plt.figure()\n",
    "x_1.sample(10).plot(range(10), plot_par=True)\n",
    "plt.figure()\n",
    "x_2.sample(10).plot(range(10), plot_par=True)\n",
    "\n",
    "# Print the measurements and the mean of the measurements\n",
    "print('measurements:', measurement)\n",
    "print('measurements mean:', np.mean(measurement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

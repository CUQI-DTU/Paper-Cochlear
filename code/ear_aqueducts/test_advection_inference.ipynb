{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test advection-diffusion model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import cuqi\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from cuqi.distribution import Gaussian, JointDistribution, GMRF, Gamma\n",
    "from cuqi.geometry import Continuous2D\n",
    "from cuqi.pde import TimeDependentLinearPDE\n",
    "from cuqi.model import PDEModel\n",
    "from copy import deepcopy\n",
    "from custom_distribution import MyDistribution\n",
    "from advection_diffusion_inference_utils import parse_commandline_args,\\\n",
    "    read_data_files,\\\n",
    "    create_domain_geometry,\\\n",
    "    create_PDE_form,\\\n",
    "    create_prior_distribution,\\\n",
    "    create_exact_solution_and_data,\\\n",
    "    set_the_noise_std,\\\n",
    "    sample_the_posterior,\\\n",
    "    create_experiment_tag,\\\n",
    "    plot_experiment,\\\n",
    "    save_experiment_data,\\\n",
    "    Args,\\\n",
    "    build_grids,\\\n",
    "    create_time_steps,\\\n",
    "    plot_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up run arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "noise_level_list= [\"fromDataVar\" , \"fromDataAvg\", \"avgOverTime\", 0.1, 0.2]\n",
    "args.noise_level = noise_level_list[1]\n",
    "args.animal = 'm1'\n",
    "args.ear = 'l'\n",
    "args.num_ST = 0\n",
    "args.inference_type =  'advection_diffusion' \n",
    "args.unknown_par_type ='custom_1'\n",
    "#args.unknown_par_value = [100]\n",
    "args.rbc = 'fromData' #'none'#'fromData'\n",
    "#args.unknown_par_value = ['m1:l:NUTS:constant:100.0:real:heterogeneous:1000:0.1:v:April22:2024:a::4:5@../../../Collab-BrainEfflux-Data/April_2x_2024_b']\n",
    "args.version = 'v200824_temp'\n",
    "Gibbs = False\n",
    "tag = create_experiment_tag(args)\n",
    "print(tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(args))\n",
    "args.data_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times, locations, real_data, real_std_data = read_data_files(args)\n",
    "# The left boundary condition is given by the data  \n",
    "real_bc_l = abs(real_data.reshape([len(locations), len(times)])[0,:])\n",
    "if args.rbc == 'fromData':\n",
    "    real_bc_r = abs(real_data.reshape([len(locations), len(times)])[-1,:])\n",
    "else:\n",
    "    real_bc_r = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STEP 4: Create the PDE grid and coefficients grid\n",
    "#----------------------------------------------------\n",
    "# PDE and coefficients grids\n",
    "L = locations[-1]*1.01\n",
    "coarsening_factor = 5\n",
    "n_grid_c = 20\n",
    "grid, grid_c, grid_c_fine, h, n_grid = build_grids(L, coarsening_factor, n_grid_c)\n",
    "\n",
    "#%% STEP 5: Create the PDE time steps array\n",
    "#------------------------------------------\n",
    "tau_max = 30*60 # Final time in sec\n",
    "cfl = 4 # The cfl condition to have a stable solution\n",
    "         # the method is implicit, we can choose relatively large time steps \n",
    "tau = create_time_steps(h, cfl, tau_max)\n",
    "\n",
    "#%% STEP 6: Create the domain geometry\n",
    "#-------------------------------------\n",
    "G_c = create_domain_geometry(grid_c, args.inference_type)\n",
    "\n",
    "# STEP 7: Create the PDE form\n",
    "#----------------------------\n",
    "PDE_form = create_PDE_form(real_bc_l, real_bc_r,\n",
    "                           grid, grid_c, grid_c_fine, n_grid, h, times,\n",
    "                           args.inference_type)\n",
    "\n",
    "# STEP 8: Create the CUQIpy PDE object\n",
    "#-------------------------------------\n",
    "PDE = TimeDependentLinearPDE(PDE_form,\n",
    "                             tau,\n",
    "                             grid_sol=grid,\n",
    "                             method='backward_euler', \n",
    "                             grid_obs=locations,\n",
    "                             time_obs=times) \n",
    "\n",
    "# STEP 9: Create the range geometry\n",
    "#----------------------------------\n",
    "G_cont2D = Continuous2D((locations, times))\n",
    "\n",
    "# STEP 10: Create the CUQIpy PDE model\n",
    "#-------------------------------------\n",
    "A = PDEModel(PDE, range_geometry=G_cont2D, domain_geometry=G_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDE.time_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 11: Create the prior distribution\n",
    "#---------------------------------------\n",
    "#x = create_prior_distribution(G_c, args.inference_type)\n",
    "#x1 = GMRF(np.ones(G_c.par_dim-1)*np.sqrt(300),\n",
    "#            0.2,\n",
    "#            bc_type='neumann')\n",
    "#x2 = Gaussian(0.5, 0.3**2)\n",
    "#x = MyDistribution([x1, x2], geometry=G_c )\n",
    "x = create_prior_distribution(G_c, args.inference_type)\n",
    "\n",
    "\n",
    "#from cuqi.distribution import GMRF\n",
    "#x = GMRF(np.ones(G_c.par_dim)*np.sqrt(300), 0.2, geometry=G_c, bc_type='neumann')\n",
    "\n",
    "Ns = 10\n",
    "samples_x = x.sample(Ns)\n",
    "samples_x.plot(range(Ns), plot_par=True)\n",
    "plt.figure()\n",
    "samples_x.funvals.plot(range(Ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prior CI\n",
    "x.sample(1000).funvals.plot_ci(95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different prior\n",
    "x_alternative = cuqi.distribution.GMRF(np.ones(G_c.par_dim)*np.sqrt(100), 2, geometry=G_c, bc_type='neumann')\n",
    "x_alternative.sample(1000).plot_ci(95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and plot exact data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_a =0.245 #np.sqrt(0.9)\n",
    "x_true, exact_data = create_exact_solution_and_data(A, args.unknown_par_type, args.unknown_par_value, a=sqrt_a, grid_c=grid_c)\n",
    "plot_time_series(times, locations, exact_data.reshape([len(locations), len(times)]))\n",
    "\n",
    "plt.figure()\n",
    "plot_time_series(times, locations, real_data.reshape([len(locations), len(times)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDE.assemble(x_true)\n",
    "sol, _ = PDE.solve()\n",
    "print(sol.shape)\n",
    "\n",
    "plt.plot(grid, sol)\n",
    "\n",
    "len(tau)\n",
    "plt.figure()\n",
    "x_true.funvals.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STEP 13: Create the data distribution\n",
    "#----------------------------------------\n",
    "# First, illustrate how different noise levels setups affect the std\n",
    "print(\"Standard deviation values\")\n",
    "plt.figure()\n",
    "for item in noise_level_list:\n",
    "    s_noise_temp = set_the_noise_std(\n",
    "        args.data_type, item, exact_data,\n",
    "        None, real_std_data, G_cont2D)\n",
    "    print('\\n**noise_level option**:', item)\n",
    "    print('**STD of the noise**:')\n",
    "    print(s_noise_temp)\n",
    "    # plot noise level\n",
    "    if isinstance(s_noise_temp, np.ndarray):\n",
    "        plt.plot(s_noise_temp, label=str(item))\n",
    "    else:\n",
    "        plt.plot(s_noise_temp*np.ones(G_cont2D.par_dim), label=str(item))\n",
    "plt.legend()\n",
    "plt.title('Noise level')\n",
    "plt.xlabel('data point index i\\n data point for the same location are grouped together')\n",
    "plt.ylabel('std of the noise')\n",
    "\n",
    "# Second, set the noise level\n",
    "s_noise = set_the_noise_std(args.data_type, args.noise_level, exact_data,\n",
    "                                None, real_std_data, G_cont2D)\n",
    "\n",
    "print(\"The applied noise level is: \", s_noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if Gibbs:\n",
    "    s = Gamma(1, 500)\n",
    "    s_samples = s.sample(1000)\n",
    "    s_samples.plot_trace()\n",
    "    s_true = 1/s_noise**2\n",
    "    print(s_true)\n",
    "    y_h = Gaussian(A(x), lambda s: 1/s, geometry=G_cont2D)\n",
    "else:\n",
    "    y = Gaussian(A(x), s_noise**2, geometry=G_cont2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples of noisy data and plot the noisy data and the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Gibbs:\n",
    "    noisy_data_h = y_h(x=x_true, s=s_true).sample()\n",
    "\n",
    "else:\n",
    "    noisy_data = y(x=x_true).sample()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(14, 3))\n",
    "plt.sca(ax[0])\n",
    "plot_time_series(times, locations, exact_data.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "plt.title('Exact data')\n",
    "\n",
    "if Gibbs:\n",
    "    plt.sca(ax[1])\n",
    "    plot_time_series(times, locations, noisy_data_h.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "    plt.title('Noisy data (hyper prior)')\n",
    "    diff_h = noisy_data_h - exact_data\n",
    "    plt.sca(ax[2])\n",
    "    lines, labels = plot_time_series(times, locations, diff_h.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "    plt.title('Difference (hyper prior)')\n",
    "    # Noise to signal ratio\n",
    "    print('Noise to signal ratio (synthitic data) (hyper prior): ', np.linalg.norm(diff_h)/np.linalg.norm(noisy_data_h))\n",
    "else:\n",
    "\n",
    "    plt.sca(ax[1])\n",
    "    plot_time_series(times, locations, noisy_data.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "    plt.title('Noisy data')\n",
    "    diff = noisy_data - exact_data\n",
    "    plt.sca(ax[2])\n",
    "    lines, labels = plot_time_series(times, locations, diff.reshape([len(locations), len(times)]), plot_legend=False)\n",
    "    plt.title('Difference')\n",
    "    # Noise to signal ratio\n",
    "    print('Noise to signal ratio (synthitic data): ', np.linalg.norm(diff)/np.linalg.norm(noisy_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('STD to signal ratio (real data): ', np.linalg.norm(real_std_data)/np.linalg.norm(real_data))\n",
    "\n",
    "fig2 = plt.figure()\n",
    "# turn off axis\n",
    "plt.axis('off')\n",
    "plt.legend(lines, labels, loc='center',ncol=3)\n",
    "#figure size\n",
    "fig2.set_size_inches(14, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Bayesian model and sample the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bayesian model\n",
    "#--------------------------\n",
    "if not Gibbs:\n",
    "\n",
    "    BP = cuqi.problem.BayesianProblem(x, y)\n",
    "    BP.set_data(y=noisy_data)\n",
    "    BP.posterior.enable_FD()\n",
    "    x0 = np.ones(G_c.par_dim)*10\n",
    "    x0[-1] = 1\n",
    "    #map = BP.MAP(x0=x0)\n",
    "    #BP.UQ(100)\n",
    "    MH = cuqi.experimental.mcmc.MH(BP.posterior, initial_point=x0)\n",
    "    MH.warmup(10)\n",
    "    MH.sample(10)\n",
    "\n",
    "if Gibbs:\n",
    "    joint = cuqi.distribution.JointDistribution(x, y_h, s)\n",
    "    joint_post = joint(y_h=noisy_data_h)\n",
    "    sampling_strategy = {\n",
    "        \"x\" : cuqi.experimental.mcmc.NUTSNew(max_depth=10),\n",
    "        \"s\" : cuqi.experimental.mcmc.ConjugateNew()\n",
    "    }\n",
    "    \n",
    "    sampler_h = cuqi.experimental.mcmc.HybridGibbsNew(joint_post, sampling_strategy)\n",
    "    \n",
    "    sampler_h.warmup(50)\n",
    "    sampler_h.sample(200)\n",
    "    samples_h = sampler_h.get_samples()\n",
    "    \n",
    "    samples_h[\"x\"].plot_ci()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Gibbs:\n",
    "    samples = MH.get_samples()\n",
    "    samples.plot_ci(exact=x_true)\n",
    "    print(np.mean(MH._acc))\n",
    "    print(samples.mean()[-1])\n",
    "    print(x_true[-1])\n",
    "    plt.figure()\n",
    "    samples.plot_trace()\n",
    "    samples.compute_ess()\n",
    "\n",
    "if Gibbs:\n",
    "    samples_h[\"s\"].plot_ci(exact=s_true)\n",
    "    plt.figure()\n",
    "    samples_h[\"x\"].plot_ci(95, exact=x_true)\n",
    "    plt.figure()\n",
    "    samples_h[\"s\"].plot_trace()\n",
    "    plt.figure()\n",
    "    samples_h[\"x\"].plot_trace()\n",
    "    print(s_true)\n",
    "    #samples_h[\"s\"].plot_ci(95, exact=s_true)\n",
    "    print(samples_h[\"s\"].burnthin(150).mean())\n",
    "    \n",
    "    inferred_s_noise = 1/np.sqrt(samples_h[\"s\"].burnthin(150).mean())\n",
    "    print(s_noise)\n",
    "    print(inferred_s_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo forward with a = 1 , a = 2, a = 3 (instability in the last case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = BP.MAP(x0=x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map.plot(label='MAP')\n",
    "x_true.plot(label='True solution', marker='x')\n",
    "plt.plot(x0, 'o', label='Initial guess')\n",
    "mean = np.concatenate((x.distribution_list[0].mean.flatten(), x.distribution_list[1].mean))\n",
    "plt.plot(mean, '.', label='Prior mean')\n",
    "plt.legend(loc='lower center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(x_true[:-1])**2\n",
    "max(x_true[:-1])**2\n",
    "print(x_true[-1])\n",
    "print(map[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = Pec * min_diffusion / L\n",
    "Pec_min = a * L / min_diffusion\n",
    "Pec_max = a * L / max_diffusion\n",
    "Pec_min = 0.9**2 * 1900 / 21 = 72.9?\n",
    "Pec_max = 0.9**2 * 1900 / 200 = 8.19?\n",
    "\n",
    "\n",
    "a = 0.9 micro m/s\n",
    "\n",
    "L = ~1900 micro m\n",
    "\n",
    "min_diffusion = 21 micro m^2/s\n",
    "\n",
    "http://calliope.dem.uniud.it/CLASS/ING-AMB/ade.pdf\n",
    "\n",
    "0.01 to get pec of 0.1\n",
    "\n",
    "0.01 * 2000 / (15)**2 = 20 /225 = 0.0889\n",
    "a = sqrt(0.01) = 0.1\n",
    "\n",
    "CA only inference \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/(0.3*0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_diff = x_true[:-1].max()**2\n",
    "print(\"max_diff\", max_diff)\n",
    "min_diff = x_true[:-1].min()**2\n",
    "print(\"min_diff\", min_diff) \n",
    "sqrt_a2 = np.sqrt(0.06)\n",
    "a2 = sqrt_a2**2\n",
    "L = 400\n",
    "Pec = a2*L/max_diff\n",
    "print(\"Pec\", Pec)\n",
    "print(\"a\", a2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pec_std= 1\n",
    "a2_std = pec_std*max_diff/L\n",
    "print(\"a_std\", a2_std)\n",
    "print(\"a_std_sqrt\", np.sqrt(a2_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A look into the prior distribution of the advection\n",
    "\n",
    "1. Extract the prior distribution of the advection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prior_a = deepcopy(x.distribution_list[1])\n",
    "\n",
    "print(prior_a)\n",
    "print(prior_a.geometry)\n",
    "prior_a.sample(10000).funvals.plot_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Equip it with the right geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = cuqi.geometry.MappedGeometry(cuqi.geometry.Discrete(1), map = x.geometry.map)\n",
    "prior_a.geometry = geom\n",
    "prior_a_samples = prior_a.sample(10000)\n",
    "prior_a_samples.funvals.plot_trace()\n",
    "print(\"mean\", prior_a_samples.funvals.mean())\n",
    "print(\"std\", prior_a_samples.funvals.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now we look at Peclet number distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pec_prior_max = deepcopy(prior_a)\n",
    "pec_prior_geometry_max = cuqi.geometry.MappedGeometry(\n",
    "    cuqi.geometry.Discrete(1),\n",
    "    map = lambda val: val**2*L/min_diff)\n",
    "pec_prior_max.geometry = pec_prior_geometry_max\n",
    "pec_prior_max_samples = pec_prior_max.sample(10000)\n",
    "pec_prior_max_samples.funvals.plot_trace()\n",
    "print(\"max peclet\")\n",
    "print(\"L\", L)\n",
    "print(\"min_diffusion\", min_diff)\n",
    "print(\"pec_prior_max mean\", pec_prior_max_samples.funvals.mean())\n",
    "print(\"pec_prior_max std\", pec_prior_max_samples.funvals.std())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pec_prior_min = deepcopy(prior_a)\n",
    "pec_prior_geometry_min = cuqi.geometry.MappedGeometry(\n",
    "    cuqi.geometry.Discrete(1),\n",
    "    map = lambda val: val**2*L/max_diff)\n",
    "pec_prior_min.geometry = pec_prior_geometry_min\n",
    "pec_prior_min_samples = pec_prior_min.sample(10000)\n",
    "pec_prior_min_samples.funvals.plot_trace()\n",
    "print(\"min peclet\")\n",
    "print(\"L\", L)\n",
    "print(\"max_diff\", max_diff)\n",
    "print(\"pec_prior_min mean\", pec_prior_min_samples.funvals.mean())\n",
    "print(\"pec_prior_min std\", pec_prior_min_samples.funvals.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Function of peclet number given the advection speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_adv_pec_max = lambda a: a * L / min_diff\n",
    "a_grid = np.linspace(0, 1, 100)\n",
    "plt.plot(a_grid, map_adv_pec_max(a_grid))\n",
    "plt.xlabel('a')\n",
    "plt.ylabel('Peclet number')\n",
    "plt.title('Peclet number as a function of a (min diffusivity)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_adv_pec_min = lambda a: a * L / max_diff\n",
    "a_grid = np.linspace(0, 1, 100)\n",
    "plt.plot(a_grid, map_adv_pec_min(a_grid))\n",
    "plt.xlabel('a')\n",
    "plt.ylabel('Peclet number')\n",
    "plt.title('Peclet number as a function of a (max diffusivity)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

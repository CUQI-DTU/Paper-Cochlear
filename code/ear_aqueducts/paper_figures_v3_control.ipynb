{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper control results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from advection_diffusion_inference_utils import (read_data_files,\n",
    "                                                 read_experiment_data,\n",
    "                                                 all_animals,\n",
    "                                                 all_ears,\n",
    "                                                 plot_time_series,\n",
    "                                                 create_time_steps,\n",
    "                                                 build_grids,\n",
    "                                                 create_domain_geometry,\n",
    "                                                 create_PDE_form)\n",
    "\n",
    "\n",
    "from cuqi.geometry import Continuous2D\n",
    "from cuqi.pde import TimeDependentLinearPDE\n",
    "from cuqi.model import PDEModel\n",
    "import scipy.stats as sps\n",
    "import cuqi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_A(data_diff):\n",
    "    # STEP 2: Read time and location arrays\n",
    "    #----------------------------------------\n",
    "    args = data_diff['experiment_par']\n",
    "    (real_times, real_locations, real_data, real_std_data,\n",
    "     diff_locations, real_data_diff, real_std_data_diff) = read_data_files(args)\n",
    "    \n",
    "\n",
    "    # The left boundary condition is given by the data  \n",
    "    real_bc_l = real_data.reshape([len(real_locations), len(real_times)])[0,:]\n",
    "\n",
    "    real_bc_l[real_bc_l<0] = 0\n",
    "\n",
    "    # The right boundary condition is given by the data (if rbc is not \"zero\")\n",
    "    if args.rbc == 'fromData':\n",
    "        raise Exception('Right boundary condition from data not supported')\n",
    "    elif args.rbc == 'fromDataClip':\n",
    "        real_bc_r = real_data.reshape([len(real_locations), len(real_times)])[-1,:]\n",
    "\n",
    "        real_bc_r[real_bc_r<0] = 0\n",
    "\n",
    "    \n",
    "    else:\n",
    "        real_bc_r = None\n",
    "    \n",
    "    if args.u0_from_data:\n",
    "        real_u0 = real_data.reshape([len(real_locations), len(real_times)])[:,0]\n",
    "\n",
    "        real_u0[real_u0<0] = 0\n",
    "\n",
    "    \n",
    "    # locations, including added locations that can be used in synthetic \n",
    "    # case only\n",
    "    if len(args.add_data_pts) > 0:\n",
    "        locations = np.concatenate((real_locations, np.array(args.add_data_pts)))\n",
    "        # reorder the locations\n",
    "        locations = np.sort(locations)\n",
    "        diff_locations = locations[:-1]\n",
    "    else:\n",
    "        locations = real_locations\n",
    "    # times\n",
    "    times = real_times\n",
    "    # STEP 4: Create the PDE grid and coefficients grid\n",
    "    #----------------------------------------------------\n",
    "    # PDE and coefficients grids\n",
    "    factor_L = 1.2 if args.rbc == 'zero' else 1.01\n",
    "    L = locations[-1]*factor_L\n",
    "    coarsening_factor = 5\n",
    "    n_grid_c = 20\n",
    "    grid, grid_c, grid_c_fine, h, n_grid = build_grids(L, coarsening_factor, n_grid_c)\n",
    "    \n",
    "    # Step 4.1: Create u0\n",
    "    #-----------------------\n",
    "    if args.u0_from_data:\n",
    "        # interpolate real_u0 to the grid\n",
    "        u0 = np.interp(grid, locations, real_u0)\n",
    "    else:\n",
    "        u0 = None\n",
    "    \n",
    "    # STEP 5: Create the PDE time steps array\n",
    "    #------------------------------------------\n",
    "    tau_max = 30*60 # Final time in sec\n",
    "    cfl = 5 # The cfl condition to have a stable solution\n",
    "             # the method is implicit, we can choose relatively large time steps \n",
    "    tau = create_time_steps(h, cfl, tau_max, args.adaptive)\n",
    "    \n",
    "    # STEP 6: Create the domain geometry\n",
    "    #-------------------------------------\n",
    "    G_c = create_domain_geometry(grid_c, args.inference_type)\n",
    "    \n",
    "    # STEP 7: Create the PDE form\n",
    "    #----------------------------\n",
    "    PDE_form = create_PDE_form(real_bc_l, real_bc_r,\n",
    "                               grid, grid_c, grid_c_fine, n_grid, h, times,\n",
    "                               args.inference_type,\n",
    "                               u0=u0)\n",
    "    # STEP 8: Create the CUQIpy PDE object\n",
    "    #-------------------------------------\n",
    "    PDE = TimeDependentLinearPDE(PDE_form,\n",
    "                                 tau,\n",
    "                                 grid_sol=grid,\n",
    "                                 method='backward_euler', \n",
    "                                 grid_obs=locations,\n",
    "                                 time_obs=times,\n",
    "                                 data_grad=args.data_grad) \n",
    "    \n",
    "    # STEP 9: Create the range geometry\n",
    "    #----------------------------------\n",
    "    if args.data_grad:\n",
    "        G_cont2D = Continuous2D((diff_locations, times))\n",
    "    else:\n",
    "        G_cont2D = Continuous2D((locations, times))\n",
    "    \n",
    "    # STEP 10: Create the CUQIpy PDE model\n",
    "    #-------------------------------------\n",
    "    A = PDEModel(PDE, range_geometry=G_cont2D, domain_geometry=G_c)\n",
    "\n",
    "    return A\n",
    "def read_all_scenarios(scenarios_dir, scenarios_subdir, scenario_tags_list):\n",
    "    \n",
    "    data_list = []\n",
    "    for i, case in enumerate(scenario_tags_list):\n",
    "            \n",
    "            # Read the experiment data\n",
    "            data_list.append(\n",
    "                read_experiment_data(\n",
    "                    scenarios_dir+\"/\"+scenarios_subdir[i],\n",
    "                    scenario_tags_list[i]\n",
    "                    ))\n",
    "\n",
    "    return data_list\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_dir =  \"/Users/amal/Documents/research_code/CUQI-DTU/Collab-BrainEfflux-Data/A_Considered_for_the_paper/results_jan6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read case diff 1\n",
    "scenarios_subdir = [\"paperV4CASynthDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp\"]\n",
    "\n",
    "scenario_tags_list = [\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff1.npz_100.0_syntheticFromDiffusion_heterogeneous_200_std_0.1_paperV4CASynthDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp__0_5_0.1_fromDataClip\",\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff1.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp__0_5_-1.0_fromDataClip\",\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff1.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp__0_5_0.5_fromDataClip\",\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff1.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff1_zerou0_update_hp__0_5_2.0_fromDataClip\"]\n",
    "\n",
    "data_list_diff1 = read_all_scenarios(scenarios_dir, scenarios_subdir, scenario_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read case diff 2\n",
    "scenarios_subdir = [\"paperV4CASynthDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp\"]\n",
    "\n",
    "scenario_tags_list = [\n",
    "    \"m3_l_NUTSWithGibbs_synth_diff2.npz_100.0_syntheticFromDiffusion_heterogeneous_200_std_0.1_paperV4CASynthDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp__0_5_0.1_fromDataClip\",\n",
    "    \"m3_l_NUTSWithGibbs_synth_diff2.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp__0_5_-1.0_fromDataClip\",\n",
    "    \"m3_l_NUTSWithGibbs_synth_diff2.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp__0_5_0.5_fromDataClip\",\n",
    "    \"m3_l_NUTSWithGibbs_synth_diff2.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff2_zerou0_update_hp__0_5_2.0_fromDataClip\"]\n",
    "\n",
    "data_list_diff2 = read_all_scenarios(scenarios_dir, scenarios_subdir, scenario_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read case diff 3\n",
    "scenarios_subdir = [\"paperV4CASynthDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp\",\n",
    "                    \"paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp\"]\n",
    "\n",
    "scenario_tags_list = [\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff3.npz_100.0_syntheticFromDiffusion_heterogeneous_200_std_0.1_paperV4CASynthDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp__0_5_0.1_fromDataClip\",\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff3.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp__0_5_-1.0_fromDataClip\",\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff3.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp__0_5_0.5_fromDataClip\",\n",
    "    \"m1_r_NUTSWithGibbs_synth_diff3.npz_100.0_syntheticFromDiffusion_advection_diffusion_200_std_0.1_paperV4CASynthAdvDiff_Gauess_gibbs_scale_all_diff3_zerou0_update_hp__0_5_2.0_fromDataClip\"]\n",
    "# e72362512cb8bf8fa68931bdadfdf6d33c4bad6f paperV4CASynthDiff_Gauess_gibbs_scale_all_diff3\n",
    "data_list_diff3 = read_all_scenarios(scenarios_dir, scenarios_subdir, scenario_tags_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_control_case(data_list):\n",
    "    # create a 4 by 5 plot, each row is for a different case\n",
    "    # in the data_list. The first column is for the exact data,\n",
    "    # the second column is for the predicted data (mean reconstruction data)\n",
    "    # the third column is for the diffusion CI \n",
    "    # the fourth column is for the advection prior and posterior\n",
    "    # the fifth column is for the hyperparamter prior and posterior\n",
    "    # note that the first row does not have the advection parameter\n",
    "\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
    "    for i in range(len(data_list)):\n",
    "        # create A\n",
    "        A = create_A(data_list[i])\n",
    "\n",
    "        real_times, real_locations, real_data, real_std_data, diff_locations, real_data_diff, real_std_data_diff = read_data_files(data_list[i]['experiment_par'])\n",
    "\n",
    "        # Plot the exact data\n",
    "        plt.sca(axs[i, 0])\n",
    "        \n",
    "        exact_data = \\\n",
    "            A(data_list[i][\"exact\"], is_par=False) \n",
    "        non_grad_exact_data = A.pde._solution_obs\n",
    "        plot_time_series(real_times, real_locations,\n",
    "                         non_grad_exact_data,\n",
    "                         plot_legend=False)\n",
    "\n",
    "        # Plot the mean reconstruction data\n",
    "        plt.sca(axs[i, 1])\n",
    "\n",
    "        mean_recon_data = \\\n",
    "            A(data_list[i][\"x_samples\"].funvals.mean(), is_par=False)\n",
    "        non_grad_mean_recon_data = A.pde._solution_obs\n",
    "        \n",
    "\n",
    "\n",
    "        plot_time_series(real_times,\n",
    "                        real_locations,  \n",
    "                        non_grad_mean_recon_data,\n",
    "                        plot_legend=False)\n",
    "        \n",
    "        # print norm of the difference\n",
    "        print(np.linalg.norm(non_grad_mean_recon_data-non_grad_exact_data))\n",
    "\n",
    "        # Plot the credibility interval of the inferred diffusion parameter\n",
    "        plt.sca(axs[i, 2])\n",
    "        if i==0:\n",
    "\n",
    "            data_list[i]['x_samples'].funvals.plot_ci(68, exact=data_list[i]['exact'])\n",
    "        \n",
    "        else:\n",
    "            cuqi.samples.Samples(data_list[i]['x_samples'].samples[:-1,:], geometry=data_list[0]['x_samples'].geometry).plot_ci( 68, plot_envelope_kwargs={'facecolor': 'g'}, color='g') \n",
    "            exact=cuqi.array.CUQIarray(data_list[i]['exact'].to_numpy()[:-1], is_par=False, geometry=data_list[0]['x_samples'].geometry)\n",
    "            exact.plot(color='C1')\n",
    "            # remove legend\n",
    "            plt.gca().legend().remove()\n",
    "        # for i != 0, plot the prior and posterior of the advection parameter\n",
    "        plt.sca(axs[i, 3])\n",
    "        v_min = -3\n",
    "        v_max = 3\n",
    "        if i != 0:\n",
    "\n",
    "            # plot the prior and posterior of the advection parameter\n",
    "\n",
    "            var_a_sqrt = 0.752**2\n",
    "            var_a = 2*var_a_sqrt**2\n",
    "            prior2 =cuqi.distribution.Gaussian(0, var_a) #TODO: store\n",
    "\n",
    "            cuqi.utilities.plot_1D_density(prior2, v_min=v_min, v_max=v_max, color='b',label='prior')\n",
    "            #plt.hist(data_adv_list[i]['x_samples'].samples[-1,:].flatten(), bins=50, alpha=0.5, label='$a$', color='orange')\n",
    "\n",
    "            \n",
    "            kde = sps.gaussian_kde(data_list[i]['x_samples'].samples[-1,:].flatten())\n",
    "            x = np.linspace(v_min, v_max, 100)\n",
    "            l1 = plt.plot(x, kde(x), color='black', label='posterior')\n",
    "            \n",
    "            # plot vertical line true value\n",
    "            true_a = data_list[i]['experiment_par'].true_a\n",
    "            plt.axvline(true_a, color='r', linestyle='--')\n",
    "            \n",
    "        # write ess\n",
    "        ESS_val = data_list[i]['x_samples'].compute_ess()\n",
    "        plt.text(-2.8, 0.8, 'ESS (min): \\n'+str(int(np.min(ESS_val))), fontsize=8)\n",
    "        plt.text(-2.8, 0.6, 'ESS (mean): \\n'+str(int(np.mean(ESS_val))), fontsize=8)\n",
    "        plt.text(-2.8, 0.4, 'ESS (max): \\n'+str(int(np.max(ESS_val))), fontsize=8)\n",
    "        plt.ylim(0, 1.1)\n",
    "        plt.xlim(v_min, v_max)\n",
    "\n",
    "\n",
    "        # plot the gibbs hyperparameter\n",
    "        plt.sca(axs[i, 4])\n",
    "        s = cuqi.distribution.Gamma(0.9, 0.5) #TODO: store\n",
    "        s_samples = s.sample(10000)\n",
    "        v_min = 0\n",
    "        v_max = 3\n",
    "        \n",
    "        #cuqi.utilities.plot_1D_density(s, v_min=v_min, v_max=v_max, color='b',label='prior')\n",
    "        kde_1 = sps.gaussian_kde(1/np.sqrt(s_samples.samples.flatten())) \n",
    "        kde_2 = sps.gaussian_kde(1/np.sqrt(data_list[i]['s_samples'].samples.flatten()))\n",
    "        x = np.linspace(v_min, v_max, 100)\n",
    "        l1 = plt.plot(x, kde_1(x), color='blue', label='prior')\n",
    "        l2 = plt.plot(x, kde_2(x), color='black', label='posterior')\n",
    "        plt.legend()\n",
    "\n",
    "        # plot true value\n",
    "        true_s = float(data_list[i]['experiment_par'].noise_level.split('_')[1])\n",
    "        plt.axvline(true_s, color='r', linestyle='--')\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_control_case_v2(data_list):\n",
    "    # create a 4 by 5 plot, each row is for a different case\n",
    "    # in the data_list. The first column is for the exact data,\n",
    "    # the second column is for the predicted data (mean reconstruction data)\n",
    "    # the third column is for the diffusion CI\n",
    "    # the fourth column is for the advection prior and posterior\n",
    "    # the fifth column is for the hyperparamter prior and posterior\n",
    "    # note that the first row does not have the advection parameter\n",
    "\n",
    "    fig, axs = plt.subplots(4, 5, figsize=(15, 10))\n",
    "    for i in range(len(data_list)):\n",
    "        # create A\n",
    "        A = create_A(data_list[i])\n",
    "\n",
    "        (\n",
    "            real_times,\n",
    "            real_locations,\n",
    "            real_data,\n",
    "            real_std_data,\n",
    "            diff_locations,\n",
    "            real_data_diff,\n",
    "            real_std_data_diff,\n",
    "        ) = read_data_files(data_list[i][\"experiment_par\"])\n",
    "\n",
    "        # noisy non gradient data\n",
    "        # print keys of data_list[i]\n",
    "        # print(data_list[i].keys())\n",
    "        noisy_grad_data = data_list[i][\"data\"]\n",
    "        mean_recon_data = A(data_list[i][\"x_samples\"].funvals.mean(), is_par=False)\n",
    "        non_grad_mean_recon_data = A.pde._solution_obs\n",
    "\n",
    "        exact_data = A(data_list[i][\"exact\"], is_par=False)\n",
    "        non_grad_exact_data = A.pde._solution_obs\n",
    "        # Plot the mean reconstruction data\n",
    "        plt.sca(axs[i, 1])\n",
    "\n",
    "        plot_time_series(\n",
    "            real_times, real_locations, non_grad_mean_recon_data, plot_legend=False\n",
    "        )\n",
    "        plot_time_series(\n",
    "            real_times,\n",
    "            real_locations,\n",
    "            non_grad_exact_data,\n",
    "            plot_legend=False,\n",
    "            marker=\"*\",\n",
    "            linestyle=\"\",\n",
    "        )\n",
    "        plt.ylim(-500, 4000)\n",
    "\n",
    "        # print norm of the difference\n",
    "        # print(np.linalg.norm(non_grad_mean_recon_data-non_grad_exact_data))\n",
    "\n",
    "        # Plot the exact data\n",
    "        plt.sca(axs[i, 0])\n",
    "\n",
    "\n",
    "        plot_time_series(\n",
    "            real_times,\n",
    "            diff_locations,\n",
    "            exact_data.reshape([len(diff_locations), len(real_times)]),\n",
    "            plot_legend=False,\n",
    "        )\n",
    "        plot_time_series(\n",
    "            real_times,\n",
    "            diff_locations,\n",
    "            noisy_grad_data.reshape([len(diff_locations), len(real_times)]),\n",
    "            plot_legend=False,\n",
    "            marker=\"*\",\n",
    "            linestyle=\"\"\n",
    "        )\n",
    "        plot_time_series(\n",
    "            real_times,\n",
    "            diff_locations,\n",
    "            mean_recon_data.reshape([len(diff_locations), len(real_times)]),\n",
    "            plot_legend=False,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "        plt.ylim(-20, 20)\n",
    "\n",
    "        # Plot the credibility interval of the inferred diffusion parameter\n",
    "        plt.sca(axs[i, 2])\n",
    "        if i == 0:\n",
    "\n",
    "            data_list[i][\"x_samples\"].funvals.plot_ci(68, exact=data_list[i][\"exact\"])\n",
    "\n",
    "        else:\n",
    "            cuqi.samples.Samples(\n",
    "                data_list[i][\"x_samples\"].samples[:-1, :],\n",
    "                geometry=data_list[0][\"x_samples\"].geometry,\n",
    "            ).plot_ci(68, plot_envelope_kwargs={\"facecolor\": \"g\"}, color=\"g\")\n",
    "            exact = cuqi.array.CUQIarray(\n",
    "                data_list[i][\"exact\"].to_numpy()[:-1],\n",
    "                is_par=False,\n",
    "                geometry=data_list[0][\"x_samples\"].geometry,\n",
    "            )\n",
    "            exact.plot(color=\"C1\")\n",
    "            # remove legend\n",
    "            plt.gca().legend().remove()\n",
    "        # for i != 0, plot the prior and posterior of the advection parameter\n",
    "        plt.sca(axs[i, 3])\n",
    "        v_min = -3\n",
    "        v_max = 3\n",
    "        if i != 0:\n",
    "\n",
    "            # plot the prior and posterior of the advection parameter\n",
    "\n",
    "            var_a_sqrt = 0.752**2\n",
    "            var_a = 2 * var_a_sqrt**2\n",
    "            prior2 = cuqi.distribution.Gaussian(0, var_a)  # TODO: store\n",
    "\n",
    "            cuqi.utilities.plot_1D_density(\n",
    "                prior2, v_min=v_min, v_max=v_max, color=\"b\", label=\"prior\"\n",
    "            )\n",
    "            # plt.hist(data_adv_list[i]['x_samples'].samples[-1,:].flatten(), bins=50, alpha=0.5, label='$a$', color='orange')\n",
    "\n",
    "            kde = sps.gaussian_kde(data_list[i][\"x_samples\"].samples[-1, :].flatten())\n",
    "            x = np.linspace(v_min, v_max, 100)\n",
    "            l1 = plt.plot(x, kde(x), color=\"black\", label=\"posterior\")\n",
    "\n",
    "            # plot vertical line true value\n",
    "            true_a = data_list[i][\"experiment_par\"].true_a\n",
    "            plt.axvline(true_a, color=\"r\", linestyle=\"--\")\n",
    "\n",
    "        # write ess\n",
    "        ESS_val = data_list[i][\"x_samples\"].compute_ess()\n",
    "        # plt.text(-2.8, 0.8, 'ESS (min): \\n'+str(int(np.min(ESS_val))), fontsize=8)\n",
    "        # plt.text(-2.8, 0.6, 'ESS (mean): \\n'+str(int(np.mean(ESS_val))), fontsize=8)\n",
    "        # plt.text(-2.8, 0.4, 'ESS (max): \\n'+str(int(np.max(ESS_val))), fontsize=8)\n",
    "        plt.ylim(0, 1.1)\n",
    "        plt.xlim(v_min, v_max)\n",
    "\n",
    "        # plot the gibbs hyperparameter\n",
    "        plt.sca(axs[i, 4])\n",
    "        s = cuqi.distribution.Gamma(0.9, 0.5)  # TODO: store\n",
    "        s_samples = s.sample(10000)\n",
    "        v_min = 0\n",
    "        v_max = 2\n",
    "\n",
    "        # cuqi.utilities.plot_1D_density(s, v_min=v_min, v_max=v_max, color='b',label='prior')\n",
    "        kde_1 = sps.gaussian_kde(1 / np.sqrt(s_samples.samples.flatten()))\n",
    "        kde_2 = sps.gaussian_kde(\n",
    "            1 / np.sqrt(data_list[i][\"s_samples\"].samples.flatten())\n",
    "        )\n",
    "        x = np.linspace(v_min, v_max, 100)\n",
    "        l1 = plt.plot(x, kde_1(x), color=\"blue\", label=\"prior\")\n",
    "        l2 = plt.plot(x, kde_2(x), color=\"black\", label=\"posterior\")\n",
    "        # log y scal\n",
    "        plt.yscale(\"log\")\n",
    "        plt.ylim(1e-15, 10)\n",
    "        plt.legend()\n",
    "\n",
    "        # plot true value\n",
    "        true_s = float(data_list[i][\"experiment_par\"].noise_level.split(\"_\")[1])\n",
    "        plt.axvline(true_s, color=\"r\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots directory \n",
    "import os\n",
    "if not os.path.exists('figures/control'):\n",
    "    os.makedirs('figures/control')\n",
    "#plot_control_case(data_list_diff1)\n",
    "#plt.savefig('figures/control/control_diff1.png')\n",
    "\n",
    "#plot_control_case(data_list_diff2)\n",
    "#plt.savefig('figures/control/control_diff2.png')\n",
    "\n",
    "#plot_control_case(data_list_diff3)\n",
    "#plt.savefig('figures/control/control_diff3.png')\n",
    "plot_control_case_v2(data_list_diff1)\n",
    "plt.savefig('figures/control/control_diff1_v2.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenicsproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

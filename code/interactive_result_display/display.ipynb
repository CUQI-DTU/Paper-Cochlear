{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display of Ear aqueduct results (finite difference code - diffusion only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of images that live in `../../Collab-BrainEfflux-Data/April_2x_2024`\n",
    "find all files in the directory of the form *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case =  \"April_2x_2024_b\"\n",
    "#case =  \"v06May2024_a\"\n",
    "#case = \"v21May2024_c\"\n",
    "#case = \"v20May2024_const_b\"\n",
    "# case = \"v16Aug2024_real\"\n",
    "case = \"v16Aug2024_synth_large_a\"\n",
    "#case = \"v16Aug2024_synth_small_a\"\n",
    "\n",
    "\n",
    "if case == \"April_2x_2024_b\":\n",
    "    images = !find ../../../Collab-BrainEfflux-Data/April_2x_2024_b/ -name \"*.png\"\n",
    "    noise_idx= -8\n",
    "\n",
    "if case == \"v06May2024_a\":\n",
    "    images = !find ../../../Collab-BrainEfflux-Data/v06May2024_a/ -name \"*New*.png\"\n",
    "    noise_idx= -6\n",
    "\n",
    "if case == \"v21May2024_c\":\n",
    "    images = !find ../../../Collab-BrainEfflux-Data/v21May2024_c/ -name \"*.png\"\n",
    "    noise_idx= -6\n",
    "\n",
    "if case == \"v20May2024_const_b\":\n",
    "    images = !find ../../../Collab-BrainEfflux-Data/v20May2024_const_b/ -name \"*.png\"\n",
    "    noise_idx= -6\n",
    "\n",
    "\n",
    "if case == \"v16Aug2024_real\":\n",
    "    images = !find ../../../Collab-BrainEfflux-Data/v16Aug2024_real/ -name \"*.png\"\n",
    "    noise_idx= -6\n",
    "    num_samples_labels_offset = 2\n",
    "    \n",
    "if case == \"v16Aug2024_synth_large_a\":\n",
    "    images = !find ../../../Collab-BrainEfflux-Data/v16Aug2024_synth_large_a/ -name \"*.png\"\n",
    "    num_samples_labels_offset = 2\n",
    "    noise_idx= -8\n",
    "\n",
    "if case == \"v16Aug2024_synth_small_a\":\n",
    "    images = !find ../../../Collab-BrainEfflux-Data/v16Aug2024_synth_small_a/ -name \"*.png\"\n",
    "    num_samples_labels_offset = 2\n",
    "    noise_idx= -8\n",
    "\n",
    "\n",
    "images = np.array(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)\n",
    "print(images[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of labels for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_labels = np.array([image.split('/')[-1].split('_')[1] for image in images])\n",
    "ear_labels = np.array([image.split('/')[-1].split('_')[2] for image in images])\n",
    "sampler_labels = np.array([image.split('/')[-1].split('_')[3] for image in images])\n",
    "data_type_labels = np.array([image.split('/')[-1].split('_')[6] for image in images])\n",
    "num_samples_labels = np.array([image.split('/')[-1].split('_')[8+num_samples_labels_offset] for image in images])\n",
    "CA_labels = np.array([image.split('/')[-1].split('_')[-1].split('.')[0] for image in images])\n",
    "ST_labels = np.array([image.split('/')[-1].split('_')[-2] for image in images])\n",
    "noise_labels = np.array([image.split('/')[-1].split('_')[noise_idx] for image in images])\n",
    "\n",
    "# Additional label\n",
    "animal_ear_labels = np.array([animal_labels[i] + '_' + ear_labels[i] for i in range(len(images))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_titles = np.array([f\"{animal_labels[i]}_{ear_labels[i]}_{sampler_labels[i]}_{data_type_labels[i]}_{num_samples_labels[i]}_{CA_labels[i]}_{ST_labels[i]}_{noise_labels[i]}\" for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('animal_labels:', np.unique(animal_labels))\n",
    "print('ear_labels:', np.unique(ear_labels))\n",
    "print('sampler_labels:', np.unique(sampler_labels))\n",
    "print('data_type_labels:', np.unique(data_type_labels))\n",
    "print('num_samples_labels:', np.unique(num_samples_labels))\n",
    "print('CA_labels:', np.unique(CA_labels))\n",
    "print('ST_labels:', np.unique(ST_labels))\n",
    "print('noise_labels:', np.unique(noise_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter images based on labels (create idx of images to keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize idx\n",
    "idx = np.arange(len(images))\n",
    "\n",
    "# remove images where number of samples is 20\n",
    "#idx = np.where(np.logical_and(np.array(num_samples_labels) != '20',\n",
    "#               np.array(num_samples_labels) != '200' ,\n",
    "#               np.array(num_samples_labels) != '200000'))[0] \n",
    "\n",
    "# Keep images where sampler is NUTS\n",
    "idx = np.intersect1d(idx, np.where(np.array(sampler_labels) == 'NUTS')[0])\n",
    "\n",
    "# keep only images where noise is 0.1\n",
    "# idx = np.intersect1d(idx, np.where(np.array(noise_labels) == 'var')[0])\n",
    "\n",
    "# keep only images where number of ST measurements is 4\n",
    "#idx = np.intersect1d(idx, np.where(np.array(ST_labels) == '4')[0])\n",
    "\n",
    "# keep only animal m1\n",
    "idx = np.intersect1d(idx, np.where(np.array(animal_labels) == 'm1')[0])\n",
    "\n",
    "print(len(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification = animal_ear_labels[idx]\n",
    "classification = noise_labels[idx]\n",
    "ipyplot.plot_class_tabs(images[idx],\n",
    "                        classification,\n",
    "                        max_imgs_per_tab=10, img_width=400, show_url=False,\n",
    "                        custom_texts=image_titles[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From case April to case May 6: The following changes:\n",
    "Updates about the prior:\n",
    "- Prior choice was: `GMRF(np.ones(G_c.par_dim), 2, geometry=G_c, bc_type='neumann')`\n",
    "- New prior choice: `GMRF(np.ones(G_c.par_dim)*np.sqrt(300), 0.2, geometry=G_c, bc_type='neumann')`\n",
    "\n",
    "Update about the noise level:\n",
    "- (This is still being looked at) it seems all noise level set up were probably correct except for the case when we average the noise std. Now it is corrected.\n",
    "- Do we need to take into account the subsampling of the data?\n",
    "- noise over time added\n",
    "\n",
    "May 6 experiment is synthetic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
